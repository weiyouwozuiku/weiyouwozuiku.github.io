---
title: MySQL整理与总结
author: 不二
img: >-
  https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/PageImg/KV存储/MySQL整理与总结.jpeg
mathjax: true
top: true
date: 2022-03-01 21:06:10
tags: MySQL
categories: KV存储
---

## MySQL基础架构

![MySQL逻辑架构图.png](https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/KV存储/MySQL整理与总结/MySQL逻辑架构图.png)

MySQL大致可以分成Server层和存储引擎层。

### 连接器

连接器负责跟客户端建立链接、获取权限、维持和管理链接。

一个用户成功创建连接后，即使对该用户修改权限，也不会影响当前存在连接的权限。修改完成之后，只有创建新的连接采用使用新的权限。

可以使用`show processlist;`查看连接状态。

客户端通过参数`wait_timeout`来控制没有动静的连接，默认一般是8小时。

使用长链接可能导致MySQL占用内存上涨很快。因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源只有在连接断开时才释放。长期积累可能导致内存占用过大，被系统强行OOM，从现象看就是MySQL异常重启。

对此解决方案：

- 定期断开长连接
- 如果是MySQL5.7之后的版本，可以在执行一个较大内存的操作时，通过执行`MySQL_reset_connection`来重新初始化连接资源。此时连接会恢复成刚创建完时的状态

### 查询缓存

MySQL拿到一个查询请求后，在老版本会先去查询缓存。之前执行的语句及其结果可能会以kv对的形式存在内存中。key是查询语句，value是查询结果。

但是不推荐使用缓存。因为**通常情况下MySQL的缓存利大于弊。**

查询缓存的失效非常频繁。只要对一个表的更新，这个表上的所有查询缓存就会被清空。对于更新压力较大的数据库来说，查询缓存的命中率很低。**除非你的业务是一个静态表，很长时间才更新一次。**

通过设置参数`query_cache_type`为`DEMAND`，这样默认的SQL语句都不使用查询缓存。需要是显式指定。例如：

```sql
select SQL_cache * from T where ID=...;
```

MySQL8.0之后没有查询缓存这个功能了。

### 分析器

分析器进行sql的词法分析，知道你要做什么。

#### 解析器

解析器处理语法和解析查询，生成对应的解析树。

#### 预处理器

预处理器进一步检查解析树的合法。比如：数据表和数据列是否存在，别名是否有歧义。如果通过则生成新的解析树，再交给优化器。详见《高性能MySQL》6.4.3查询优化处理。

### 优化器

优化器是在表里面有多个索引时，决定使用哪个索引；或者一个语句有多个表join的时候，决定各个表的连接顺序。知道要怎么做。

### 执行器

开始执行时会首先检查相应表你的权限。在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。

如果有权限，打开表继续执行，执行器会根据表的引擎定义，使用这个引擎提供的接口。如果命中索引的话可以在执行器阶段就直接通过索引查找，没有命中索引就遍历查找每行记录。

在数据库的慢查询日志中可以看到一个`rows_examined`字段，表示这个语句执行过程中扫描了多少行。

在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此**引擎扫描行数在rows_examined并不是完全相同**。

### 日志

#### redo log

redo log是属于InnoDB特有的日志，属于存储引擎层，记录了这个页“做了什么改动”。

MySQL利用WAL（Write-Ahead Logging）技术，先写日志再落磁盘。具体来说就是当一条记录需要更新时，InnoDB引擎就会先把记录写在redo log中，并更新内存，此时更新算完成。等到InnoDB在恰当的时间会将这个更新操作写入磁盘。

InnoDB的redo log大小是固定的。

![redo_log示意图.png](https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/KV存储/MySQL整理与总结/redo_log示意图.png)

`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。`checkpoint` 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

`wirte pos`与`checkpoint`之间的空间就是还可以存放的容量。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。

`innodb_flush_log_at_trx_commit`设置为1表示每次事务的redo log直接持久化到磁盘。

#### binlog

binlog属于Sever层，binlog不具备`crash-safe`的能力。

binlog有两种模式，statement格式会记录sql语句，row格式会记录行的内容，记两条更新前后都有。

`sync_binlog`设置为1表示每次事务的binlog直接持久化到磁盘。

#### 二者对比

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
1. redo log是**物理日志**，记录的是在某个数据页上做了什么修改；binlog是**逻辑日志**，记录的是这个语句的原始逻辑。
1. redo log是循环写，空间固定会用完；binlog是写到一定大小后切换到下一个，并不会覆盖之前的日志。

#### 整体运行逻辑

![update语句执行流程.png](https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/KV存储/MySQL整理与总结/update语句执行流程.png)

有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行简单的 update 语句`update table T set c=c+1 where ID=2`时的内部流程。

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

在上述过程中，redo存在“两阶段提交”，即prepare和commit。

两阶段提交的目的是**为了让两份日志之间的逻辑一致**。

如果要实现一定时间内的数据库数据恢复，可以通过binlog中存储的所有逻辑操作实现以及定期的整库备份。

当需要恢复数据到指定的某一秒时，那么可以：

1. 首先找到最近的一次全量备份。将这个表恢复到临时表。
2. 从备份的时间点开始，将备份的binlog依次取出，重放到误操作之前的那个时刻。
3. 再对比临时表与线上表之前的差异，同步到线上表。

基于数据恢复的过程，可以论证为什么需要进行两阶段提交。这里不妨使用反证法，即两种情况：1. 先写redo log再写binlog 2. 先写binlog再写redo log。

针对情况1：假设redo log完成，binlog没有执行，MySQL进程异常重启。redo log保证了数据在系统重启后还能恢复，但是此时binlog中并没有相应的原始逻辑记录，这会导致当前数据能依据redo log恢复，但是之后通过binlog恢复则不存在这次操作的记录，也就没有相应的数据。

针对情况2：假设binlog完成，redo log没有执行，MySQL进程异常重启。由于redo log没有写，恢复后这个事务无效。数据为原本的数据。但是binlog中记录了修改数据的原始逻辑，之后用binlog恢复时就会多出一个事务来。

因此，不使用两阶段提交，数据库的状态就可能和用它日志恢复恢复出来的库的状态不一致。

除了数据恢复的场景，在扩容的时候，需要一些备库来增加系统的读能力的时候。现在主流的做法是全量备份加上应用binlog实现。

redo log和binlog都能表示事务的提交状态，而两阶段保持逻辑上的一致。

## 事务

**事务的支持在引擎层实现**。

ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。

### 隔离性与隔离级别

当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，需要在二者之间寻找一个平衡点。

SQL 标准的事务隔离级别包括：

- 读未提交（read uncommitted）：是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交（read committed）：是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读（repeatable read）：是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化（serializable ）：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

![事务隔离级别描述.png](https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/KV存储/MySQL整理与总结/事务隔离级别描述.png)

接着这幅图描述下四种隔离级别的区别：

- 读未提交：V1，V2，V3都是2
- 读提交：V1是1，V2和V3都是2
- 可重复读：V1和V2都是1，V3是2
- 串行化：在事务B执行update操作时，会被锁住，直到事务A提交后，事务B才能继续执行。因此V1,V2都是1，V3才是2。

实际上，数据库会创建一个视图，访问时以视图的逻辑为准，因此针对上述的四种隔离级别：

- 读未提交：直接返回记录上的最新值，没有视图
- 读提交：视图在每个SQL开始执行的时候创建
- 可重复读：视图在事务启动时创建，整个事务存在期间都用这个视图
- 串行化：直接用加锁的方式实现

Oracle默认隔离级别是`读提交`。因此将Oracle迁移至MySQL时为了保证隔离级别的一致，也要改成读提交。

`show variables like 'transaction_isolation’ `查看当前隔离级别。

### 事务隔离实现

下面以“可重复读”为例子解释事务隔离的实现。

在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![MVCC.jpg](https://cdn.jsdelivr.net/gh/weiyouwozuiku/weiyouwozuiku.github.io@src/source/_posts/KV存储/MySQL整理与总结/MVCC.jpg)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，**同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）**。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

回滚日志会在系统判断当没有事务需要这些回滚日志时，回滚日志就会被删除。而系统判断的方法就是**检查系统中没有比这个回滚日志更早的read-view的时候**。

**长事务[^1]意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。**

在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。导致数据量其实不大，但是产生的回滚段无法清理，只能重建整个库。

### 事务启动方式

Mysql的事务启动方式有以下几种：

- 显式启动事务语句，begin或者start transaction。配套的提交语句是commit，回滚语句是rollback。
- `set autocommit=0`这个命令会将这个线程的自动提交关闭。意味着如果你只执行一个select语句，这个事务就启动了，而不会自动提交。这个事务会持续存在直到你主动执行commit或rollback语句，或断开连接。

有些客户端连接框架默认连接成功后先执行set autocommit=0的操作，这就导致之后的查询都在事务中，如果是长连接，就会导致意外的长事务。

**建议使用set autocommit=1来启动事务。**

**针对在乎频繁使用事务的业务，推荐使用commit work and chain语法**。在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

## 索引

### 索引常用模型

#### 哈希表

哈希表做范围查询因为其不是有序的，因此大多是利用遍历实现，所以**哈希表适用于等值查询的场景。**比如 Memcached 及其他一些 NoSQL 引擎。

#### 有序数组

**有序数组在等值查询以及范围查找中性能都很优秀，但是插入操作太过麻烦，成本较高。**因此有序数组只适用于静态存储引擎。

#### 搜索树

二叉树的搜索效率高，但是实际数据库并不使用二叉树，其原因在于**索引不止存在内存中，还要写到硬盘上。**

为了减少每次查询的搜索层数，最直接的方法就是让二叉树变成多叉树。这里的叉树取决于数据块的大小。

因此多叉树因为其读写上的性能优点以及适配磁盘的访问模式，广泛应用于数据库引擎中。

#### InnoDB的索引模型

在MySQL中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引工作方式是不一样的。即使多个存储引擎支持同一类型的索引，其底层实现可能也是不一致的。下文以InnoDB存储引擎为例分析索引引擎。

**在InnoDB中表都是根据主键顺序以索引的形式存放，这种存储方式的表称之为索引组织表**。InnoDB使用了B+树索引模型，数据都在B+树上。

每个索引在InnoDB中对应一个B+树。

根据叶子节点的内容，索引类型可以区分为主键索引和非主键索引。其中主键索引的叶子节点存储的是整行数据。在InnoDB里，主键索引也叫聚簇索引。非主键索引的叶子结点的内容为主键的值，在InnoDB中也称之为二级索引。

基于主键索引和非主键索引的区别在于：

- 使用主键作为where条件的话，只需要搜索主键索引树
- 使用非主键索引作为where条件的话，需要在非主键索引树上找到相应主键，再去主键索引树上查找相应的记录，**这个过程称之为回表**

因此推荐直接使用主键进行查询。

#### InnoDB的索引维护

在明确了InnoDB中的索引结构后，就引入下一个问题即索引的维护。

B+树维护了数据的有序性，可能出现插入一个数据前，需要在相应位置后的所有数据后移。更甚一步，当前数据页满了，需要新申请新的数据页，这个过程称之为页分裂，可能导致整体空间利用率下降。

通常推荐自增主键避免这种问题，因为对于自增主键对应的数据来说，只有追加写的操作，不存在挪动记录的需要，也不会触发叶子节点的分裂。

主键长度越小，普通索引的叶子节点越小，普通索引所占用的空间也越小。

## Tip

[^1]:长事务，顾名思义就是执行时间较长，长时间未提交的事务。

## 参考文献

1. 掘金，[MySQL-长事务详解](https://juejin.cn/post/6844903945920315405)，2019
